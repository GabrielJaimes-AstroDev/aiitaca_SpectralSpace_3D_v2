import streamlit as st
import pickle
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import os
import re
from scipy.interpolate import interp1d
from sklearn.neighbors import NearestNeighbors
from io import BytesIO
import base64
import plotly.express as px
import glob
import tempfile

# Set page configuration
st.set_page_config(
    page_title="C.3D Spectral Space Analyzer",
    page_icon="ðŸ”­",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 2rem;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #0D47A1;
        margin-bottom: 1rem;
        margin-top: 1.5rem;
    }
    .info-box {
        background-color: #E3F2FD;
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
    }
    .stButton>button {
        background-color: #1E88E5;
        color: white;
    }
    .main-title {
        font-size: 1.8rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
        font-weight: bold;
    }
    .plot-container {
        background-color: #FAFAFA;
        padding: 1.5rem;
        border-radius: 0.5rem;
        margin-bottom: 1.5rem;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'model' not in st.session_state:
    st.session_state.model = None
if 'spectra_files' not in st.session_state:
    st.session_state.spectra_files = None
if 'results' not in st.session_state:
    st.session_state.results = None

def load_model(model_file):
    try:
        model = pickle.load(model_file)
        return model
    except Exception as e:
        st.error(f"Error loading model: {str(e)}")
        return None

def sanitize_filename(filename):
    invalid_chars = r'[<>:"/\\|?*]'
    return re.sub(invalid_chars, '_', filename)

def extract_molecule_formula(header):
    pattern = r"molecules=['\"]([^,'\"]+)"
    match = re.search(pattern, header)
    if match:
        formula = match.group(1)
        if ',' in formula:
            formula = formula.split(',')[0]
        return formula
    return "Unknown"

def extract_filter_params(filename):
    velo_match = re.search(r'velo(-?[0-9]+(?:\.[0-9]+)?)', filename)
    fwhm_match = re.search(r'fwhm(-?[0-9]+(?:\.[0-9]+)?)', filename)
    sigma_match = re.search(r'sigma(-?[0-9]+(?:\.[0-9]+)?)', filename)

    try:
        velo = float(velo_match.group(1)) if velo_match else None
    except Exception:
        velo = None
    try:
        fwhm = float(fwhm_match.group(1)) if fwhm_match else None
    except Exception:
        fwhm = None
    try:
        sigma = float(sigma_match.group(1)) if sigma_match else None
    except Exception:
        sigma = None

    return velo, fwhm, sigma

def get_available_filter_params(filters_dir):
    filter_files = glob.glob(os.path.join(filters_dir, "*.txt"))
    velocities = set()
    fwhms = set()
    sigmas = set()
    for filter_file in filter_files:
        velo, fwhm, sigma = extract_filter_params(os.path.basename(filter_file))
        if velo is not None:
            velocities.add(velo)
        if fwhm is not None:
            fwhms.add(fwhm)
        if sigma is not None:
            sigmas.add(sigma)
    return sorted(velocities), sorted(fwhms), sorted(sigmas)

def apply_filter_to_spectrum(spectrum_data, filter_path, allow_negative=True):
    try:
        filter_data = np.loadtxt(filter_path, comments='/')
        freq_filter_hz = filter_data[:, 0]  # Hz
        intensity_filter = filter_data[:, 1]
        freq_filter = freq_filter_hz / 1e9  # Convert to GHz

        if np.max(intensity_filter) > 0:
            intensity_filter = intensity_filter / np.max(intensity_filter)

        freq_spectrum = spectrum_data[:, 0]  # GHz
        intensity_spectrum = spectrum_data[:, 1]  # K
        interp_spec = interp1d(freq_spectrum, intensity_spectrum, kind='cubic', bounds_error=False, fill_value=0)
        spectrum_on_filter = interp_spec(freq_filter)

        filtered_intensities = spectrum_on_filter * intensity_filter
        if not allow_negative:
            filtered_intensities = np.where(filtered_intensities < 0, 0, filtered_intensities)

        filtered_freqs_hz = freq_filter * 1e9
        return np.column_stack((filtered_freqs_hz, filtered_intensities))
    except Exception as e:
        st.error(f"Error applying filter {os.path.basename(filter_path)}: {str(e)}")
        return None

def generate_filtered_spectra(spectrum_data, filters_dir, selected_velo, selected_fwhm, selected_sigma, allow_negative=True):
    filter_files = glob.glob(os.path.join(filters_dir, "*.txt"))
    filtered_spectra = []
    for filter_path in filter_files:
        filter_name = os.path.basename(filter_path)
        velo, fwhm, sigma = extract_filter_params(filter_name)
        if (velo == selected_velo and fwhm == selected_fwhm and sigma == selected_sigma):
            filtered_spectrum = apply_filter_to_spectrum(spectrum_data, filter_path, allow_negative=allow_negative)
            if filtered_spectrum is not None:
                filtered_spectra.append((filter_name, filtered_spectrum))
    return filtered_spectra

def process_uploaded_spectrum(file, reference_frequencies):
    try:
        if hasattr(file, "getvalue"):
            content = file.getvalue().decode("utf-8")
        else:
            file.seek(0)
            content = file.read().decode("utf-8")
        lines = content.split('\n')

        first_line = lines[0].strip()
        second_line = lines[1].strip() if len(lines) > 1 else ""

        formula = "Unknown"
        param_dict = {}
        data_start_line = 0

        # Format 1
        if first_line.startswith('//') and 'molecules=' in first_line:
            header = first_line[2:].strip()  # Remove the '//'
            formula = extract_molecule_formula(header)
            for part in header.split():
                if '=' in part:
                    try:
                        key, value = part.split('=')
                        key = key.strip()
                        value = value.strip("'")
                        if key in ['molecules', 'sourcesize']:
                            continue
                        try:
                            param_dict[key] = float(value)
                        except ValueError:
                            param_dict[key] = value
                    except:
                        continue
            data_start_line = 1
        # Format 2
        elif first_line.startswith('!') or first_line.startswith('#'):
            if 'molecules=' in first_line:
                formula = extract_molecule_formula(first_line)
            data_start_line = 1
        # Format 3
        else:
            data_start_line = 0
            formula = file.name.split('.')[0]

        spectrum_data = []
        for line in lines[data_start_line:]:
            line = line.strip()
            if not line or line.startswith('!') or line.startswith('#'):
                continue
            try:
                parts = line.split()
                if len(parts) >= 2:
                    try:
                        freq = float(parts[0])
                        intensity = float(parts[1])
                    except ValueError:
                        freq_str = parts[0].replace('D', 'E').replace('d', 'E')
                        intensity_str = parts[1].replace('D', 'E').replace('d', 'E')
                        freq = float(freq_str)
                        intensity = float(intensity_str)
                    if np.isfinite(freq) and np.isfinite(intensity):
                        spectrum_data.append([freq, intensity])
            except Exception as e:
                st.warning(f"Could not parse line '{line}': {e}")
                continue

        if not spectrum_data:
            st.error("No valid data points found in spectrum file")
            return None, None, None, None, None

        spectrum_data = np.array(spectrum_data)
        if spectrum_data.shape[0] == 0 or spectrum_data.shape[1] != 2:
            st.error("Spectrum data is empty or malformed after parsing.")
            return None, None, None, None, None

        if np.max(spectrum_data[:, 0]) < 1e11:
            spectrum_data[:, 0] = spectrum_data[:, 0] * 1e9  # Convert GHz to Hz
            st.info(f"Converted frequencies from GHz to Hz for {file.name}")

        try:
            interpolator = interp1d(spectrum_data[:, 0], spectrum_data[:, 1],
                                    kind='linear', bounds_error=False, fill_value=0.0)
            interpolated = interpolator(reference_frequencies)
        except Exception as e:
            st.error(f"Error interpolating spectrum: {str(e)}")
            return None, None, None, None, None

        params = [
            param_dict.get('logn', np.nan),
            param_dict.get('tex', np.nan),
            param_dict.get('velo', np.nan),
            param_dict.get('fwhm', np.nan)
        ]

        return spectrum_data, interpolated, formula, params, file.name
    except Exception as e:
        st.error(f"Error processing spectrum file: {str(e)}")
        return None, None, None, None, None

def find_knn_neighbors(training_embeddings, new_embeddings, k=5):
    if len(training_embeddings) == 0 or len(new_embeddings) == 0:
        return []
    
    k = min(k, len(training_embeddings))
    
    knn = NearestNeighbors(n_neighbors=k, metric='euclidean')
    knn.fit(training_embeddings)
    
    all_neighbor_indices = []
    for new_embedding in new_embeddings:
        distances, indices = knn.kneighbors([new_embedding])
        valid_indices = [idx for idx in indices[0] if idx < len(training_embeddings)]
        all_neighbor_indices.append(valid_indices)
    
    return all_neighbor_indices

def analyze_spectra(model, spectra_files, knn_neighbors):
    new_spectra_data = []
    new_formulas = []
    new_params = []
    new_filenames = []
    new_embeddings = []
    new_pca_components = []
    
    for file in spectra_files:
        spectrum_data, interpolated, formula, params, filename = process_uploaded_spectrum(
            file, model['reference_frequencies'])
        if interpolated is None or spectrum_data is None:
            st.warning(f"Skipping file {getattr(file, 'name', 'unknown')}: no valid data after processing.")
            continue
        scaler = model['scaler']
        pca = model['pca']
        umap_model = model['umap']
        try:
            X_scaled = scaler.transform([interpolated])
            X_pca = pca.transform(X_scaled)
            X_umap = umap_model.transform(X_pca)
        except Exception as e:
            st.warning(f"Skipping file {getattr(file, 'name', 'unknown')}: error during transformation: {str(e)}")
            continue
        new_spectra_data.append(interpolated)
        new_formulas.append(formula)
        new_params.append(params)
        new_filenames.append(filename)
        new_embeddings.append(X_umap[0])
        new_pca_components.append(X_pca[0])

    if len(new_embeddings) == 0:
        st.error("No valid spectra could be processed after filtering and transformation.")
        return None
    
    new_embeddings = np.array(new_embeddings)
    new_params = np.array(new_params)
    new_formulas = np.array(new_formulas)
    new_pca_components = np.array(new_pca_components)
    
    # Find KNN neighbors
    knn_indices = find_knn_neighbors(model['embedding'], new_embeddings, k=knn_neighbors)
    
    # Calculate average parameters on neighbors
    avg_new_params = []
    for i in range(len(new_embeddings)):
        if knn_indices and len(knn_indices) > i:
            neighbor_indices = knn_indices[i]
            if neighbor_indices:
                avg_params = [
                    np.nanmean([model['y'][idx, 0] for idx in neighbor_indices]),
                    np.nanmean([model['y'][idx, 1] for idx in neighbor_indices]),
                    np.nanmean([model['y'][idx, 2] for idx in neighbor_indices]),
                    np.nanmean([model['y'][idx, 3] for idx in neighbor_indices])
                ]
                avg_new_params.append(avg_params)
            else:
                avg_new_params.append([np.nan, np.nan, np.nan, np.nan])
        else:
            avg_new_params.append([np.nan, np.nan, np.nan, np.nan])
    
    avg_new_params = np.array(avg_new_params)
    
    return {
        'new_spectra_data': new_spectra_data,
        'new_formulas': new_formulas,
        'new_params': new_params,
        'new_filenames': new_filenames,
        'new_embeddings': new_embeddings,
        'new_pca_components': new_pca_components,
        'knn_indices': knn_indices,
        'avg_new_params': avg_new_params
    }

def create_3d_scatter(embeddings, color_values, title, color_label, color_scale='viridis', 
                      marker_size=5, selected_indices=None, selected_color='red', selected_size=10,
                      formulas=None, params=None, is_training=True, show_legend=False, legend_dict=None,
                      color_param=None):  # AÃ±adir color_param como parÃ¡metro
    fig = go.Figure()
    
    hover_text = []
    for i in range(len(embeddings)):
        if is_training and formulas is not None and params is not None:
            text = f"Index: {i}<br>Formula: {formulas[i]}<br>log(n): {params[i, 0]:.2f}<br>T_ex: {params[i, 1]:.2f} K<br>Velocity: {params[i, 2]:.2f}<br>FWHM: {params[i, 3]:.2f}"
        elif not is_training and formulas is not None:
            text = f"New Spectrum: {formulas[i]}"
        else:
            text = f"Index: {i}"
        hover_text.append(text)
    
    if show_legend and legend_dict is not None and color_param == 'formula':
        unique_formulas = list(legend_dict.keys())
        
        import plotly.express as px
        colors = px.colors.qualitative.Set1 + px.colors.qualitative.Set2 + px.colors.qualitative.Set3
        formula_colors = {formula: colors[i % len(colors)] for i, formula in enumerate(unique_formulas)}
        
        for formula in unique_formulas:
            indices = [i for i, f in enumerate(formulas) if f == formula]
            if indices:
                fig.add_trace(go.Scatter3d(
                    x=embeddings[indices, 0],
                    y=embeddings[indices, 1],
                    z=embeddings[indices, 2],
                    mode='markers',
                    marker=dict(
                        size=marker_size,
                        color=formula_colors[formula], 
                        opacity=0.7,
                        line=dict(width=0)
                    ),
                    text=[hover_text[i] for i in indices],
                    hovertemplate=
                    '<b>X</b>: %{x}<br>' +
                    '<b>Y</b>: %{y}<br>' +
                    '<b>Z</b>: %{z}<br>' +
                    '%{text}' +
                    '<extra></extra>',
                    name=formula,
                    showlegend=True
                ))
    elif show_legend and legend_dict is not None:
        unique_formulas = list(legend_dict.keys())
        for formula in unique_formulas:
            indices = [i for i, f in enumerate(formulas) if f == formula]
            if indices:
                fig.add_trace(go.Scatter3d(
                    x=embeddings[indices, 0],
                    y=embeddings[indices, 1],
                    z=embeddings[indices, 2],
                    mode='markers',
                    marker=dict(
                        size=marker_size,
                        color=[color_values[i] for i in indices],
                        colorscale=color_scale,
                        opacity=0.7,
                        line=dict(width=0)
                    ),
                    text=[hover_text[i] for i in indices],
                    hovertemplate=
                    '<b>X</b>: %{x}<br>' +
                    '<b>Y</b>: %{y}<br>' +
                    '<b>Z</b>: %{z}<br>' +
                    '%{text}' +
                    '<extra></extra>',
                    name=formula,
                    showlegend=True
                ))
    else:
        fig.add_trace(go.Scatter3d(
            x=embeddings[:, 0],
            y=embeddings[:, 1],
            z=embeddings[:, 2],
            mode='markers',
            marker=dict(
                size=marker_size,
                color=color_values,
                colorscale=color_scale,
                opacity=0.7,
                colorbar=dict(
                    title=color_label,
                    len=0.5,  
                    yanchor='middle',
                    y=0.5
                ),
                line=dict(width=0)
            ),
            text=hover_text,
            hovertemplate=
            '<b>X</b>: %{x}<br>' +
            '<b>Y</b>: %{y}<br>' +
            '<b>Z</b>: %{z}<br>' +
            '%{text}' +
            '<extra></extra>',
            name='Data points',
            showlegend=False
        ))
    
    if selected_indices is not None and len(selected_indices) > 0:
        selected_embeddings = embeddings[selected_indices]
        selected_values = color_values[selected_indices] if hasattr(color_values, '__len__') and len(color_values) == len(embeddings) else color_values
        
        fig.add_trace(go.Scatter3d(
            x=selected_embeddings[:, 0],
            y=selected_embeddings[:, 1],
            z=selected_embeddings[:, 2],
            mode='markers',
            marker=dict(
                size=selected_size,
                color=selected_color,
                opacity=1.0,
                line=dict(width=2, color='black')
            ),
            name='Selected points',
            showlegend=True
        ))
    
    fig.update_layout(
        title=title,
        scene=dict(
            xaxis_title='UMAP 1',
            yaxis_title='UMAP 2',
            zaxis_title='UMAP 3',
            camera=dict(eye=dict(x=1.5, y=1.5, z=1.5))
        ),
        height=600,
        margin=dict(l=0, r=0, b=0, t=30)
    )
    
    return fig

def create_2d_scatter(embeddings, color_values, title, color_label, color_scale='viridis', 
                      marker_size=5, selected_indices=None, selected_color='red', selected_size=10):
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=embeddings[:, 0],
        y=embeddings[:, 1],
        mode='markers',
        marker=dict(
            size=marker_size,
            color=color_values,
            colorscale=color_scale,
            opacity=0.7,
            colorbar=dict(title=color_label)
        ),
        text=[f"Index: {i}" for i in range(len(embeddings))],
        hovertemplate=
        '<b>X</b>: %{x}<br>' +
        '<b>Y</b>: %{y}<br>' +
        '<b>Value</b>: %{marker.color}<br>' +
        '<extra></extra>',
        name='Data points'
    ))
    
    if selected_indices is not None and len(selected_indices) > 0:
        selected_embeddings = embeddings[selected_indices]
        selected_values = color_values[selected_indices] if hasattr(color_values, '__len__') and len(color_values) == len(embeddings) else color_values
        
        fig.add_trace(go.Scatter(
            x=selected_embeddings[:, 0],
            y=selected_embeddings[:, 1],
            mode='markers',
            marker=dict(
                size=selected_size,
                color=selected_color,
                opacity=1.0,
                line=dict(width=2, color='black')
            ),
            name='Selected points'
        ))
    
    fig.update_layout(
        title=title,
        xaxis_title='UMAP 1',
        yaxis_title='UMAP 2',
        height=500,
        margin=dict(l=0, r=0, b=0, t=30)
    )
    
    return fig

def create_spectrum_plot(frequencies, intensities, title):
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=frequencies,
        y=intensities,
        mode='lines',
        line=dict(width=2),
        name='Spectrum'
    ))
    
    fig.update_layout(
        title=title,
        xaxis_title='Frequency (Hz)',
        yaxis_title='Intensity',
        height=400,
        margin=dict(l=0, r=0, b=0, t=30)
    )
    
    return fig

def main():
    
    st.image("NGC6523_BVO_2.jpg", use_column_width=True)
    
    col1, col2 = st.columns([1, 3])
    with col1:
        st.empty()
        
    with col2:
        st.markdown('<p class="main-title">AI-ITACA | Artificial Intelligence Integral Tool for AstroChemical Analysis</p>', unsafe_allow_html=True)
    
    st.markdown("""
    A remarkable upsurge in the complexity of molecules identified in the interstellar medium (ISM) is currently occurring, with over 80 new species discovered in the last three years. A number of them have been emphasized by prebiotic experiments as vital molecular building blocks of life. Since our Solar System was formed from a molecular cloud in the ISM, it prompts the query as to whether the rich interstellar chemical reservoir could have played a role in the emergence of life. The improved sensitivities of state-of-the-art astronomical facilities, such as the Atacama Large Millimeter/submillimeter Array (ALMA) and the James Webb Space Telescope (JWST), are revolutionizing the discovery of new molecules in space. However, we are still just scraping the tip of the iceberg. We are far from knowing the complete catalogue of molecules that astrochemistry can offer, as well as the complexity they can reach.<br><br>
    <strong>Artificial Intelligence Integral Tool for AstroChemical Analysis (AI-ITACA)</strong>, proposes to combine complementary machine learning (ML) techniques to address all the challenges that astrochemistry is currently facing. AI-ITACA will significantly contribute to the development of new AI-based cutting-edge analysis software that will allow us to make a crucial leap in the characterization of the level of chemical complexity in the ISM, and in our understanding of the contribution that interstellar chemistry might have in the origin of life.
    """, unsafe_allow_html=True)
    
    st.markdown("""
    <div class="info-box">
    <h4>About GUAPOS</h4>
    <p>The G31.41+0.31 Unbiased ALMA sPectral Observational Survey (GUAPOS) project targets the hot molecular core (HMC) G31.41+0.31 (G31) to reveal the complex chemistry of one of the most chemically rich high-mass star-forming regions outside the Galactic center (GC).</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown('<h1 class="main-header">ðŸ§ª 3D Spectral Space Analyzer</h1>', unsafe_allow_html=True)
    
    # Sidebar 
    with st.sidebar:
        st.header("Input Parameters")
        
        # Model 
        st.subheader("1. Upload Model")
        model_file = st.file_uploader("Upload trained model (PKL file)", type=['pkl'])
        
        if model_file is not None:
            if st.button("Load Model") or st.session_state.model is None:
                with st.spinner("Loading model..."):
                    st.session_state.model = load_model(model_file)
                    if st.session_state.model is not None:
                        st.success("Model loaded successfully!")
        
        # Spectra upload
        st.subheader("2. Upload Spectra")
        spectra_files = st.file_uploader("Upload spectrum files (TXT)", type=['txt'], accept_multiple_files=True)
        
        if spectra_files:
            st.session_state.spectra_files = spectra_files
        
        # Filtering of parameters
        st.subheader("3. Filter Parameters")
        filters_dir = "1.Filters"
        if os.path.exists(filters_dir):
            velocities, fwhms, sigmas = get_available_filter_params(filters_dir)
            if velocities and fwhms and sigmas:
                selected_velo = st.selectbox("Velocity", velocities, index=0)
                selected_fwhm = st.selectbox("FWHM", fwhms, index=0)
                selected_sigma = st.selectbox("Sigma", sigmas, index=0)
                consider_absorption = st.checkbox("Consider absorption lines (allow negative values)", value=False)
            else:
                st.error("No valid filters found in the '1.Filters' directory")
                selected_velo = selected_fwhm = selected_sigma = None
                consider_absorption = False
        else:
            st.error("Filters directory '1.Filters' not found")
            selected_velo = selected_fwhm = selected_sigma = None
            consider_absorption = False

        st.subheader("4. Analysis Parameters")
        knn_neighbors = st.slider("Number of KNN neighbors", min_value=1, max_value=20, value=5)

        if st.button("Generate Filtered Spectra and Analyze") and st.session_state.model is not None and st.session_state.spectra_files and selected_velo is not None:
            with st.spinner("Generating filtered spectra and analyzing..."):
                try:
                    model = st.session_state.model
                    filtered_files = []
                    for spectrum_file in st.session_state.spectra_files:

                        content = spectrum_file.getvalue().decode('utf-8')
                        lines = content.splitlines()
                        data_lines = [line for line in lines if not (line.strip().startswith('!') or line.strip().startswith('//'))]
                        try:
                            spectrum_data = np.loadtxt(data_lines)
                        except Exception:
                            st.error(f"Could not read spectrum data from {spectrum_file.name}")
                            continue

                        filtered_spectra = generate_filtered_spectra(
                            spectrum_data,
                            filters_dir,
                            selected_velo,
                            selected_fwhm,
                            selected_sigma,
                            allow_negative=consider_absorption
                        )

                        for filter_name, filtered_data in filtered_spectra:
                            file_obj = tempfile.NamedTemporaryFile(delete=False, suffix='.txt')
                            np.savetxt(file_obj, filtered_data, delimiter='\t', fmt=['%.10f', '%.6e'])
                            file_obj.seek(0)
                            file_obj.name = filter_name + "_" + spectrum_file.name
                            filtered_files.append(file_obj)
                    if not filtered_files:
                        st.error("No filters found matching the selected parameters")
                        return

                    results = analyze_spectra(model, filtered_files, knn_neighbors)
                    st.session_state.results = results
                    st.success(f"Analysis completed! Generated {len(filtered_files)} filtered spectra.")
                except Exception as e:
                    st.error(f"Error during analysis: {str(e)}")

    # Main content
    if st.session_state.model is None:
        st.info("Please upload a model file to get started.")
        return
    
    model = st.session_state.model
    
    with st.expander("Model Information", expanded=True):
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Training Samples", model.get('sample_size', 'N/A'))
        with col2:
            st.metric("PCA Components", model.get('n_components', 'N/A'))
        with col3:
            st.metric("Variance Threshold", f"{model.get('variance_threshold', 0.99)*100:.1f}%")
    
    if st.session_state.results is None:
        st.info("Upload spectrum files and click 'Analyze Spectra' to see results.")
        return
    
    results = st.session_state.results
    
    st.markdown('<div class="info-box">', unsafe_allow_html=True)
    st.write(f"**Analysis Results:** {len(results['new_embeddings'])} spectra processed and projected into 3D space")
    st.markdown('</div>', unsafe_allow_html=True)
    
    tab1, tab2, tab3, tab4 = st.tabs(["3D Projection", "2D Projection", "Spectrum View", "KNN Analysis"])
    
    with tab1:
        st.markdown('<h2 class="sub-header">3D UMAP Projection</h2>', unsafe_allow_html=True)
        
        param_options = ['logn', 'tex', 'velo', 'fwhm', 'formula']
        color_param = st.selectbox("Color by", param_options, index=4)
        
        combined_embeddings = np.vstack([model['embedding'], results['new_embeddings']])
        
        if color_param == 'formula':

            all_formulas = np.concatenate([model['formulas'], results['new_formulas']])
            unique_formulas = np.unique(all_formulas)
            formula_to_num = {formula: i for i, formula in enumerate(unique_formulas)}
            color_values = np.array([formula_to_num[f] for f in all_formulas])
            color_label = "Formula"
            color_scale = 'viridis'
            

            legend_dict = {formula: formula_to_num[formula] for formula in unique_formulas}
            show_legend = True
        else:
            param_idx = param_options.index(color_param)
            if param_idx < 4: 

                training_params = model['y'][:, param_idx]

                new_data_params = results['avg_new_params'][:, param_idx]
                color_values = np.concatenate([training_params, new_data_params])
                color_label = param_options[param_idx]
                color_scale = 'viridis'
                show_legend = False
                legend_dict = None
        
        selected_indices = list(range(len(model['embedding']), len(combined_embeddings)))
        
        all_formulas = np.concatenate([model['formulas'], results['new_formulas']])
        all_params = np.vstack([model['y'], results['avg_new_params']])
        
        fig_3d = create_3d_scatter(
            combined_embeddings, 
            color_values, 
            "3D UMAP Projection (Training + New Spectra)", 
            color_label,
            color_scale=color_scale,
            selected_indices=selected_indices,
            formulas=all_formulas,
            params=all_params,
            is_training=True,
            show_legend=show_legend,
            legend_dict=legend_dict,
            color_param=color_param  
        )
        
        st.plotly_chart(fig_3d, use_container_width=True)
        
        st.markdown('<h3 class="sub-header">New Spectrum Details</h3>', unsafe_allow_html=True)
        
        for i in range(len(results['new_embeddings'])):
            col1, col2 = st.columns([1, 2])
            
            with col1:
                st.write(f"**Spectrum {i+1}:** {results['new_filenames'][i]}")
                st.write(f"**Formula:** {results['new_formulas'][i]}")
                
                if results['knn_indices'] and len(results['knn_indices']) > i and len(results['knn_indices'][i]) > 0:
                    st.write(f"**log(n):** {results['avg_new_params'][i, 0]:.2f}")
                    st.write(f"**T_ex (K):** {results['avg_new_params'][i, 1]:.2f}")
                    st.write(f"**Velocity:** {results['avg_new_params'][i, 2]:.2f}")
                    st.write(f"**FWHM:** {results['avg_new_params'][i, 3]:.2f}")
                else:
                    st.write("**log(n):** No neighbors found")
                    st.write("**T_ex (K):** No neighbors found")
                    st.write("**Velocity:** No neighbors found")
                    st.write("**FWHM:** No neighbors found")
            
            with col2:
                spectrum_fig = create_spectrum_plot(
                    model['reference_frequencies'],
                    results['new_spectra_data'][i],
                    f"Spectrum: {results['new_filenames'][i]}"
                )
                st.plotly_chart(spectrum_fig, use_container_width=True)
    
    with tab2:
        st.markdown('<h2 class="sub-header">2D UMAP Projection</h2>', unsafe_allow_html=True)
        
        color_param_2d = st.selectbox("Color by", param_options, index=4, key='color_2d')
        
        if color_param_2d == 'formula':
            color_values_2d = color_values
            color_label_2d = "Formula"
            color_scale_2d = 'viridis'
        else:
            param_idx = param_options.index(color_param_2d)
            if param_idx < 4:  # It's a parameter
                color_values_2d = np.concatenate([model['y'][:, param_idx], results['avg_new_params'][:, param_idx]])
                color_label_2d = param_options[param_idx]
                color_scale_2d = 'viridis'
        
        fig_2d = create_2d_scatter(
            combined_embeddings, 
            color_values_2d, 
            "2D UMAP Projection (Training + New Spectra)", 
            color_label_2d,
            color_scale=color_scale_2d,
            selected_indices=selected_indices
        )
        
        st.plotly_chart(fig_2d, use_container_width=True)
    
    with tab3:
        st.markdown('<h2 class="sub-header">Spectrum Comparison</h2>', unsafe_allow_html=True)
        
        spectrum_idx = st.selectbox("Select spectrum", range(len(results['new_embeddings'])), 
                                  format_func=lambda x: results['new_filenames'][x])
        
        if spectrum_idx is not None:
            col1, col2 = st.columns(2)
            
            with col1:

                spectrum_fig = create_spectrum_plot(
                    model['reference_frequencies'],
                    results['new_spectra_data'][spectrum_idx],
                    f"Spectrum: {results['new_filenames'][spectrum_idx]}"
                )
                st.plotly_chart(spectrum_fig, use_container_width=True)
            
            with col2:

                if results['knn_indices'] and len(results['knn_indices']) > spectrum_idx:
                    neighbor_indices = results['knn_indices'][spectrum_idx]
                    
                    if neighbor_indices:
                        st.write("**K-Nearest Neighbors:**")
                        
                        neighbor_data = []
                        for idx in neighbor_indices:
                            neighbor_data.append({
                                'Formula': model['formulas'][idx],
                                'log(n)': f"{model['y'][idx, 0]:.2f}",
                                'T_ex (K)': f"{model['y'][idx, 1]:.2f}",
                                'Velocity': f"{model['y'][idx, 2]:.2f}",
                                'FWHM': f"{model['y'][idx, 3]:.2f}"
                            })
                        
                        neighbor_df = pd.DataFrame(neighbor_data)
                        st.dataframe(neighbor_df, use_container_width=True)
    
    with tab4:
        st.markdown('<h2 class="sub-header">K-Nearest Neighbors Analysis</h2>', unsafe_allow_html=True)
        
        for i in range(len(results['new_embeddings'])):
            st.markdown(f"**{results['new_filenames'][i]}** ({results['new_formulas'][i]})")
            
            if results['knn_indices'] and len(results['knn_indices']) > i:
                neighbor_indices = results['knn_indices'][i]
                
                if neighbor_indices:

                    neighbor_data = []
                    for idx in neighbor_indices:
                        neighbor_data.append({
                            'Formula': model['formulas'][idx],
                            'log(n)': f"{model['y'][idx, 0]:.2f}",
                            'T_ex (K)': f"{model['y'][idx, 1]:.2f}",
                            'Velocity': f"{model['y'][idx, 2]:.2f}",
                            'FWHM': f"{model['y'][idx, 3]:.2f}",
                            'Distance': f"{np.linalg.norm(model['embedding'][idx] - results['new_embeddings'][i]):.4f}"
                        })
                    
                    neighbor_df = pd.DataFrame(neighbor_data)
                    st.dataframe(neighbor_df, use_container_width=True)
                    
                    st.write("**Average parameters of neighbors:**")
                    avg_params = {
                        'log(n)': np.mean([model['y'][idx, 0] for idx in neighbor_indices]),
                        'T_ex (K)': np.mean([model['y'][idx, 1] for idx in neighbor_indices]),
                        'Velocity': np.mean([model['y'][idx, 2] for idx in neighbor_indices]),
                        'FWHM': np.mean([model['y'][idx, 3] for idx in neighbor_indices])
                    }
                    
                    avg_df = pd.DataFrame([avg_params])
                    st.dataframe(avg_df, use_container_width=True)
                    
                    comparison_data = {
                        'Parameter': ['log(n)', 'T_ex (K)', 'Velocity', 'FWHM'],
                        'New Spectrum': [results['avg_new_params'][i, 0], results['avg_new_params'][i, 1], results['avg_new_params'][i, 2], results['avg_new_params'][i, 3]],
                        'Neighbors Average': [avg_params['log(n)'], avg_params['T_ex (K)'], avg_params['Velocity'], avg_params['FWHM']],
                        'Difference': [
                            results['avg_new_params'][i, 0] - avg_params['log(n)'],
                            results['avg_new_params'][i, 1] - avg_params['T_ex (K)'],
                            results['avg_new_params'][i, 2] - avg_params['Velocity'],
                            results['avg_new_params'][i, 3] - avg_params['FWHM']
                        ]
                    }
                    
                    comparison_df = pd.DataFrame(comparison_data)
                    st.dataframe(comparison_df, use_container_width=True)
            
            st.markdown("---")

if __name__ == "__main__":
    main()









